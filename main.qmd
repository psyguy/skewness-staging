---
title: "Skewness and staging: Does the floor effect induce bias in multilevel AR(1) models?"
subtitle: "Reproducible codes"
author: "MH Manuel Haqiqatkhah"
format:
  html:
    code-fold: true
    code-tools: true
    code-overflow: scroll
    code-line-numbers: true
    toc: true
    toc-location: left
    toc-depth: 5
    code-summary: "Click to expand the code"
    anchor-sections: true
    reference-location: document
    citation-location: margin
  # theme:
  #   light: litera
  #   dark: darkly
  pdf:
    number-sections: true
    number-depth: 8
    toc: true
    toc-depth: 8
## For html
execute:
  enabled: true
  echo: true
  include: true
  warning: false
  error: false
  freeze: true
  cache: true
## For pdf
# execute:
#   enabled: true
#   echo: false
#   include: false
#   warning: false
#   error: false
editor: visual
bibliography: references.bib
---

# Introduction {#sec-introduction}

This document contains the reproducible code for the manuscript Skewness and staging: Does the floor effect induce bias in multilevel AR(1) models? by M. M. Haqiqatkhah, O. Ryan, and E. L. Hamaker. please cite as:

...

In this study, we simulated multilevel data from three data generating mechanisms (DGMs), namely, the AR(1, $\chi^2$AR(1), BinAR(1), and PoDAR(1) models with different parameter sets.\
For details, see the paper.

The simulation was conducted using the following modular pipeline design, inspired by Bien's R package `simulator` [-@bien_2016_SimulatorEngineStreamline], consisting of the following **components**:

A.  *Simulation*: generating the datasets
B.  *Analysis*: modeling the data
C.  *Harvesting*: collecting the relevant parameter estimates
D.  *Reporting*: making tables and plots

And the components were placed in a **pipeline**, that managed:

1.  Making the simulation design matrix that include all relevant conditions
2.  Book-keeping data files belonging to each replication of each condition
3.  Performing simulations in batch
4.  Performing Analyses in batch
5.  Collecting the data in batch

This document is structured as follows. In @sec-components, we explain the four components and the functions used therein. Then, in @sec-pipeline we explain the wrapper functions used in the pipeline, and show how the pipeline was---and can be---executed. Finally, in @sec-figures, we discuss how the harvested data was used to make the figures used in the paper (and others that were not included).

<!--# In what follows we describe the steps and provide the codes used in this study. In the other tab of this document, we provide the code to generate additional plots shown in the paper. Note that although the codes provided here are cleaned as much as possible, they are not necessarily succinctly written; some functions were written to accommodate the most general functionalities which turned out to be not necessary for the simulation study. -->

Before we begin, we need to read the scripts to include them in this document. By default, none of the scripts run here (as they are time consuming). To run the scripts of each component, you can change the following variables to `TRUE` and re-render the document:

```{r}
#| eval: true
#| code-fold: false
runComponent_Simulation <- FALSE
runComponent_Analysis <- FALSE
runComponent_Harvesting <- FALSE
runComponent_Reporting <- FALSE
```

In case you want to change the scripts (e.g., to run a smaller portion of the simulation, or try other parameters, etc.), you should look up the `kintr` parameters called in each chunk (with `<<some_param>>`) and find the corresponding code (under `## @knitr some_param`) in the `scripts` folder.

```{r}
#| label: setup
#| echo: false
#| include: false
#| eval: true

scripts <- list.files(path = "scripts/",
                      pattern = ".r|.R",
                      full.names = TRUE)

sapply(scripts, knitr::read_chunk)

runComponent_Initialization <- runComponent_Simulation | runComponent_Analysis | runComponent_Harvesting | runComponent_Reporting

library(knitr)

```

```{r, eval = runComponent_Initialization}
#| include: false
#| eval: true
<<load_packages>>
```

# Core components {#sec-components}

## The *Simulation* component

The Simulation component consists of three sets of functions:

i.  Functions that implement the DGMs and generate univariate ($N=1$) time series of length $T$ from the parameters given to them;
ii. Wrappers that interface the DGM functions;
iii. A wrapper to generate datasets (consisting on $N$ time series of length $T$) with a given DGM

### Data-generating models specifications

First we define functions for each data-generating models (DGMs) that can produce univariate, single-subject ($N=1$) time series of desired length $T$ (default: `T = 100`) with the two canonical parameters and a given random seed (default: `seed = 0`). All model(-implied) parameters are saved in a list (called `pa`).

For each model, the first observation ($X_1$) is randomly drawn from the model-implied marginal distribution, to eliminate the need for removing the burn-in window in the beginning of the data. After the data is generated, in case the argument `only.ts` is set to be `TRUE`, the raw data (as a vector of length `T`) is returned. Otherwise, the function calculates empirical dynamic ($\phi$) and marginal ($\mu$, $\sigma^2$, and $\gamma$) parameters based on the simulated data, and save it in a list (`Empirical.Parameters`). Furthermore, two `r ifelse(knitr::is_html_output(), r"($\mathrm{\LaTeX{}}$)", r"(\LaTeX{})")`-ready strings (`Model.Description` and `Model.Description.Short`) are made which include a summary of the model parameters (that can be used, e.g., in plots). Finally, in case `only.ts != TRUE`, the function returns a list consisting of the time series (stored in `x`), verbal description of the dataset (`Model.Description` and `Model.Description.Short`), theoretical (i.e., model-implied) parameters (`Model.Parameters`), and empirical (i.e., sample) estimated parameters (`Empirical.Parameters`).

::: panel-tabset
#### The AR(1) model

The canonical parameters of the AR(1) model with normally distributed residuals (which we referred to as `NAR(1)` in the simulation) are the autoregressive parameter $\phi$ (default: `phi = 0.4`), mean $\mu$ (default: `Mean = 50`), and the marginal variance $\sigma^2$ (default: `var.marginal = 4`). Based on the marginal variance, the residual variance (`var.resid`) is calculated via $\sigma^2_\epsilon = \sigma^2 (1 - \phi^2)$.

##### Construction

The time series is constructed by first generating a zero-centered time series $\tilde X_t$ (`x_cent`). To do so, first the initial observation in the time series (`x_cent[1]`) is sampled from normal distribution with mean zero and a variance equal to the marginal variance of the model:

$$
\tilde X_1 \sim \mathcal{N}(0, \sigma^2)
$$

Then, the remainder of the time series is generated using the definition of the AR(1) model (not that the here the residual variance is used in the normal distribution):

$$
\begin{aligned}
\tilde X_{t} &= \phi \tilde X_{t-1} + \epsilon_{t} \\
\epsilon_{t} &\sim \mathcal{N}(0, {\sigma^2_{\epsilon}})
\end{aligned}
$$ Finally, the mean is added to the centered zero-centered time series to reach the final time series with mean $\mu$:

$$
X_t = \tilde X_t + \mu
$$

##### Code

```{r, eval = runComponent_Simulation}
<<dgm_nar>>
```

#### The $\chi^2$AR(1) model

The canonical parameters of the $\chi^2$AR(1) model (which we referred to as `ChiAR(1)` in the simulation) are the autoregressive parameter $\phi$ (default: `phi = 0.4`), and degrees of freedom $\nu$ (default: `nu = 3`). We set the intercept to zero (`c = 0`).[^1]

##### Construction

Similar to the AR(1) model, we need to sample the first observation of the $\chi^2$AR(1) model from its marginal distribution. However, since this model does not have a closed-form marginal distribution, as an approximation, we instead sample `x[1]` from a $\chi^2$ distribution with $\nu$ degrees of freedom:

$$
X_1 \sim \chi^2(\nu)
$$

Then, we generate the remainder of the time series using the definition of the $\chi^2$AR(1) model:

$$
\begin{aligned}
X_{t} &= c + \phi X_{t-1} + a_{t} \\
a_{t} &\sim \chi^2(\nu).
\end{aligned}
$$

##### Code

```{r, eval = runComponent_Simulation}
<<dgm_chiar>>
```

#### The BinAR(1) model

The canonical parameters of the BinAR(1) model (which we referred to as `BinAR(1)` in the simulation) are the survival probability $\alpha$ (default: `alpha = 0.5`) and the revival probability $\beta$ (default: `beta = 0.4`). By default, the maximum value on scale $k$ was set to `k = 10`.

##### Construction

We first calculate the $\theta$ parameter, which characterizes the marginal distribution of the BinaR(1) model:

$$
\theta = \frac{k \beta}{1-(\alpha-\beta)}
$$ Then we draw $X_1$ (`x[1]`) from the marginal distribution of the model:

$$
X_1 \sim Binom(k, \theta)
$$

The rest of time series is generated sequentially, for each time point $t$, by drawing values for the number of survived (`S_t[t]`) and revived (`R_t[t]`) elements of the BinAR(1) model based on the previous observations ($X_{t-1}$), and then adding them:

$$
\begin{aligned}
S_{t} &\sim Binom(X_{t-1}, \alpha) \\
R_t &\sim Binom(k -X_{t-1}, \beta) \\
X_{t} &= S_t + R_t
\end{aligned}
$$

##### Code

```{r, eval = runComponent_Simulation}
<<dgm_binar>>
```

#### The PoDAR(1) model

The canonical parameters of the PoDAR(1) model (which we referred to as `PoDAR(1)` in the simulation) are the persistence probability $\tau$ (default: `tau = 0.7`) and the average rate $\lambda$ (default: `lambda = 0.5`).

##### Construction

To generate the time series, we first draw the first observation $X_1$ (`x[1]`) from a Poisson distribution with rate $\lambda$:

$$
X_1 \sim Poisson(\lambda)
$$

And generate the rest of the time series by first drawing $Z_t$ from a Poisson distribution with rate $\lambda$ and $P_t$ from a binomial distribution with size probability of success $\tau$ (that is equivalent to a Bernoulli distribution with probability $\tau$). Then, we calculate $X_t$ based on the previous observation (`x[t-1]`) and values of $Z_t$ (`Z_t[t]`) and $P_t$ (`P_t[t]`), using the definition of the PoDAR(1) model:

$$
\begin{aligned}
Z_t &\sim Poisson(\lambda) \\
P_t &\sim Binom(1, \tau) \\
X_t &= P_t X_{t-1} + (1-P_t) Z_t
\end{aligned}
$$

##### Code

```{r, eval = runComponent_Simulation}
<<dgm_podar>>
```
:::

[^1]: The $\chi^2$AR(1), in a more general form, can have an intercept ($X_{t} = c + \phi X_{t-1} + a_t, \quad a_t \sim \chi^2(\nu)$. Since the intercept was set to zero in the simulation study, we discussed a zero-intercept version of this model ($c=0$) in the paper. See the Supplemental Materials for more details.

### General DGM wrappers

Given that, in each model, two canonical parameters characterize the dynamic and marginal features of the generated time series, and given that we have analytic formulas that link the canonical parameters to the model-implied $\phi$, $\mu$, $\sigma^2$, and $\gamma$, we use a function (`dgm_parameterizer`) to calculate canonical parameters from two given parameters, and make a complete list of parameters (called `pa`). This list also includes non-parameter variables, importantly, the time series length $T$ (saved in `pa$T`) and the random seed used in the `dgm_*` functions (saved in `pa$seed`). A wrapper function (`dgm_generator`) is used as an interface to all `dgm_*` functions, which first makes sure the given parameters are sufficient for data generation, makes a complete parameter list `pa` with the help of `dgm_parameterizer`, and passes `pa` to the respective DGM generating function.

::: panel-tabset
#### Parameter conversions

The function `dgm_parameterizer` calculates canonical/model-implied parameters of a given DGM (specified using the `Model` argument) based on the parameters given to it as arguments, and saves them in a list of parameters (`pa`), which s returned by the function. The function makes sure that the set of parameters provided are sufficient to characterize the dynamic parameter of the model (i.e., the autoregression $\phi$) and at least one of the marginal parameters (importantly, the mean $\mu$) but giving default values to some parameters.

```{r, eval = runComponent_Simulation}
<<dgm_parameterizer>>
```

#### Wrapper around `dgm_*` functions

The function `dgm_generator` gets a set of parameters (either as separate arguments, or a list of parameters, like the one returned by `dgm_parameterizer`), saves them in a list called `pa`. It checks whether $\phi$ is included in the list (if not, sets the default value `pa$phi = 0.2`), and checks if at least one other parameter (which, together with $\phi$, is required to characterize the marginal properties of the DGMs) is calculated for it (if not, it sets the default value `pa$Mean = 5` for $\mu$). Furthermore, if the DGM name, time series length, and the random seed are not provided, it gives them default values (respectively: `Model = "ChiAR(1)"`, `T = 100`, and `seed = 0`) and adds them to `pa`.

Then, it passes the `pa` list to `dgm_parameterizer` to do the necessary conversions to complete the list of canonical and model-implied parameters. Finally, given the model name, it checks if non-canonical parameters $k$ and $c$ are set (otherwise assigns appropriate defaults to them), and passes the complete parameter list to the respective DGM function.

```{r, eval = runComponent_Simulation}
<<dgm_generator>>
```
:::

### Dataset generation

The machinery described above can be used to generate individual ($N=1$) time series. However, for the simulation study, we need datasets comprising of multiple ($N=25, 50, 100$) individuals. As we discussed in the paper, in our study, all individuals in a dataset of a DGM share the same autoregressive parameter ($\phi_i=0.4$) and the individual differences are only in the individual means ($\mathbb{\mu} = [\mu_1 , \mu_2, \dots, \mu_N]$). Thus, we write a function (`dgm_make.sample`) that can generate, for each DGM, a dataset of $N$ individuals based on an $N$-dimensional vector of individual means, all with the same $\phi_i$. We then need to find the appropriate parameters for the level-2 distributions (Gaussian and $\chi^2$ distributions) for each DGM, such that the we get a considerable proportion of individuals with considerably high skewness while respecting the lower and upper bounds of values supported by each model. Finally, with a wrapper function (`make_datasets`), we facilitate making dataset by automatically generating the means vector suitable for each DGM.

::: panel-tabset
#### Making individual datasets

The function `dgm_make.sample` generates a dataset of time series of length `T` with the autoregressive parameter `phi` from a desired DGM (determined by the `Model` argument) given a vector of means (passed as the argument `Means`). The length of `Means` determine the number of individuals in the dataset (`N <- length(Means)`). If `Means` is not provided, a randomly generated vector of $N = 100$ is used as default. Since each individual time series is generated with a random seed, we need a vector of `N` unique seeds, which can be provided using the `seeds` argument. In case `seeds` is not provided, it is generated based on the provided means (`seeds.from.means`), and if it is a scalar, the seeds vector is created by adding the scalar to the `seeds.from.means` (which would allow generating different datasets with the same mean distributions).

```{r, eval = runComponent_Simulation}
<<dgm_make.sample>>
```

#### Determining level-2 distribution parameters

For each alternative DGM---the $\chi^2$AR(1), BinAR(1), and PoDAR(1) models---we should determine appropriate parameters for the level-2 distribution of means such that we have enough skewness in the generated datasets. To do so, we make a function (`Mean.vs.Skewness`) to help us experiment with different values for $\mu$ and $\sigma^2$ (of the Gaussian level-2 distribution) and $\nu$ (of the $\chi^2$ level-2 distribution) for each alternative DGM. Note that we start by generating more than enough samples for each distribution ($10 \times N$) and subsample $N$ values after applying the model-specific lower and upper bounds.

```{r}
#| eval: true
#| echo: false
#| include: false
<<Mean.vs.Skewness>>
```

We notice that we get the desired distribution of skewness with the following parameters:

| Model         | $\mu$ | $\sigma^2$ | $\nu$ |
|---------------|-------|------------|-------|
| $\chi^2$AR(1) | 10    | 10         | 5     |
| BinAR(1)      | 2     | 1          | 2.9   |
| PoDAR(1)      | 4     | 4          | 1.5   |

: Parameters of level-2 distribution of means

Giving us the following distributions:

```{r}
#| eval: false
#| echo: false
#| include: false


gaussian.means <-
  wrap_elements(Mean.vs.Skewness("Chi2AR",
     l2.mean = 10,
     l2.var = 10,
     seed = 1)) /
  wrap_elements(Mean.vs.Skewness("BinAR",
     l2.mean = 2,
     l2.var = 1,
     seed = 4)) /
  wrap_elements(Mean.vs.Skewness("PoDAR",
                   l2.mean = 4,
     seed = 2))

chi2.means <-
  wrap_elements(Mean.vs.Skewness("Chi2AR",
     chi2.df = 5,
     seed = 1)) /
  wrap_elements(Mean.vs.Skewness("BinAR",
     chi2.df = 2.9,
     seed = 1)) /
  wrap_elements(Mean.vs.Skewness("PoDAR",
                   chi2.df = 1.5,
     seed = 4))

ggsave("Mean_vs_Skewness.png",
       wrap_elements(gaussian.means) +
       wrap_elements(chi2.means),
       path = "additional-files",
       width = 40,
       height = 60,
       units = "cm")
```

![](additional-files/Mean_vs_Skewness.png)

#### Automate dataset generation

We then use a wrapper (`make_datasets`) around `dgm_make.sample` that generates datasets for all four DGMs with the appropriate level-2 parameters specified above. Note that here we first generate more than enough (i.e., $2 \times N$) samples of means to make sure we end up with $N$ samples after applying the upper and lower bounds.

```{r, eval = runComponent_Simulation}
<<make_datasets>>
```
:::

## The *Analysis* component {#sec-analysis-component}

We analyzed each dataset with the AR(1) model with fixed and random residual variance using *M*plus v. 8.1 [@muthen_2017_MplusUserGuide]. To interface *M*plus from R, we used the package `MplusAutomation` [@hallquist_2018_MplusAutomationPackageFacilitating] and wrote a function (`run_MplusAutomation`) that for each iteration of each condition would save the dataset as a `.dat` file, generate the `.inp` input script for the desired analysis type, and run the model for that dataset:

```{r, eval = runComponent_Simulation}
<<run_MplusAutomation>>
```

In each analysis, we simulated two MCMC chains (`CHAINS = 2`), and to reduce autocorrelation in the estimated parameters, by defining `THIN = 5` we asked *M*plus to save every 5th sample. By setting `BITERATIONS = 5000(2000)`, we made sure to have between 2000 to 5000 samples (after thinning) for each parameter from each chain. *M*plus considers the first half of each chain as burn-in samples and discards them, thus, in total, we got at least 2000 "independent" samples from both chains combined. Finally, with `FACTORS = ALL (500)` we asked *M*plus to draw 500 samples for each individuals when estimating level-1 parameters. We visually inspected the traceplots and autocorrelation plots of parameter estimates and of a sample of analyzed datasets and good convergence was observed. Furthermore, to make sure the number of iterations and thinning used in the analyses were sufficient, we re-analyzed two replications of each alternative DGM with Gaussian and $\chi^2$-distributed means with $N=100$ and $T=100$ with `BITERATIONS = 12500(5000)` and `THIN = 20`, which led to estimates of the parameters of interest (`unstd X.WITH.PHI`, `unstd Variances.PHI`, and `stdyx X.WITH.PHI`) almost identical (up to the third decimal) to those estimated with `BITERATIONS = 5000(2000)` and `THIN = 5` (see below).

The generated input files looked like the following. Note that the `TITLE` and `DATA` strings in the `.inp` files are unique to the dataset being analyzed and included the unique dataset seed `uSeed` (passed to `make_datasets` to generate datasets), the number of individuals in the dataset `N`, the length of the time series `T`, the model types used (`resid.fixed` or `resid.random`), and the replication number `Rep` (see @sec-book-keeping for further details).

::: panel-tabset
#### Fixed residual variance

    TITLE:
    fit_uSeed-000000_N-100_T-100_type-resid.fixed_Rep-1

    DATA:
    FILE = "fit_uSeed-000000_N-100_T-100_type-resid.fixed_Rep-1.dat";
     
    VARIABLE:
    NAMES = subject t x;
    MISSING=.;
    CLUSTER = subject;
    LAGGED = x(1);
    TINTERVAL = t(1);

    ANALYSIS:
    TYPE = TWOLEVEL RANDOM;
    ESTIMATOR = BAYES;
    PROCESSORS = 1;
    CHAINS = 2;
    THIN = 5;
    BITERATIONS = 5000(2000);

    MODEL:
    %WITHIN%
    phi | x ON x&1;
    %BETWEEN%
    x phi WITH x phi;

    OUTPUT:
    TECH1 TECH2 TECH3 TECH8 FSCOMPARISON STANDARDIZED STDYX STDY;

    PLOT:
    TYPE = PLOT3;
    FACTORS = ALL (500)

#### Random residual variance

    TITLE:
    fit_uSeed-000000_N-100_T-100_type-resid.random_Rep-1

    DATA:
    FILE = "fit_uSeed-000000_N-100_T-100_type-resid.random_Rep-1.dat";
     
    VARIABLE:
    NAMES = subject t x; 
    MISSING=.;
    CLUSTER = subject;
    LAGGED = x(1);
    TINTERVAL = t(1);

    ANALYSIS:
    TYPE = TWOLEVEL RANDOM;
    ESTIMATOR = BAYES;
    PROCESSORS = 1;
    CHAINS = 2;
    THIN = 5;
    BITERATIONS = 5000(2000);

    MODEL:
    %WITHIN%
    phi | x ON x&1;
    logv | x;
    %BETWEEN%
    x phi logv WITH x phi logv;

    OUTPUT:
    TECH1 TECH2 TECH3 TECH8 FSCOMPARISON STANDARDIZED STDYX STDY;

    PLOT:
    TYPE = PLOT3;
    FACTORS = ALL (500);

#### Comparing different `ANALYSIS` parameters

```{=html}
<iframe width="700" height="500" src="./additional-files/hyperparameters.html" title="Quarto Documentation"></iframe>
```
:::

## The *Harvesting* component {#sec-harvesting-component}

## The *Reporting* component {#sec-reporting-component}

# Pipeline {#sec-pipeline}

We implemented each of these tasks in separate functions that were essentially wrapper functions (with parallel-computing implementation) around the modular components. Using these wrapper functions, each replication of each simulated condition was saved in a separate `.rds` file. These data files were fed to the analysis wrapper function whose output was saved in separate `.rds` data files. To collect relevant parameter estimates, another wrapper function was used to read the data files and save the desired parameters in a dataframe, which then used in reporting.

## Book-keeping {#sec-book-keeping}

The outcomes of the components are saved in separate `.rds` files and indexed by unique, descriptive names, and each replication is given a unique numeric identifier that is also used as the random seed used to generate the dataset within each replication. The file names and address are stored in two dataframes along with model parameters used to generate each dataset, and these dataframes are used when reading and writing data files in other components.

## Wrapper functions {#sec-pipeline-wrapper-functions}

## Pipeline code {#sec-pipeline-code}

# Making the figures {#sec-figures}

## Simulation results

## Profiles of simulated datasets
